{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./datasets/multiclass.csv\")\n",
    "X = dataset.iloc[:,:-1].values\n",
    "Y = dataset.iloc[:,2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, {'x1': 4.148449748155552, 'x2': -5.349373873960868}),\n",
       " (0, {'x1': -6.948623942315413, 'x2': 9.261384080094093}),\n",
       " (0, {'x1': -5.837256039557852, 'x2': 10.588704071731597}),\n",
       " (2, {'x1': -5.734435901598429, 'x2': 0.614201160084101}),\n",
       " (1, {'x1': 2.829649796673452, 'x2': -4.04070236479507}),\n",
       " (0, {'x1': -4.701120134863366, 'x2': 7.904347583018205}),\n",
       " (2, {'x1': -6.723581425099838, 'x2': -1.5614959316858525}),\n",
       " (0, {'x1': -5.538625893350698, 'x2': 8.901553823281551}),\n",
       " (0, {'x1': -7.66131279774612, 'x2': 11.064073648658292}),\n",
       " (2, {'x1': -7.78033728810476, 'x2': -2.113026418071311})]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format(x, y):\n",
    "    dick = {\n",
    "        'x1': x[0],\n",
    "        'x2': x[1]\n",
    "    }\n",
    "    return (int(y), dick)\n",
    "classes = [0, 1, 2]\n",
    "feature_list = [\"x1\", \"x2\"]\n",
    "dataset = [format(x, y) for (x, y) in zip(X, Y)]\n",
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, {'x1': -6.680402206551326, 'x2': -1.5753489390588176}),\n",
       " (2, {'x1': -5.374359421101238, 'x2': -0.44941488700008303}),\n",
       " (0, {'x1': -5.519674843687177, 'x2': 9.354214545892336}),\n",
       " (1, {'x1': 3.5937185185317415, 'x2': -6.851470180887033}),\n",
       " (0, {'x1': -6.218983836376524, 'x2': 9.718364985661635}),\n",
       " (0, {'x1': -6.544115411851049, 'x2': 9.18968342946056}),\n",
       " (1, {'x1': 2.2751042604343006, 'x2': -7.325961129094093}),\n",
       " (0, {'x1': -4.332226141788491, 'x2': 9.098107690613682}),\n",
       " (1, {'x1': 2.1511114045635535, 'x2': -6.790125514745523}),\n",
       " (0, {'x1': -5.708800391089712, 'x2': 9.342260320550505})]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split feature data into train set, and test set\n",
    "random.shuffle(dataset)\n",
    "Train_set = dataset[:int(len(dataset) * 0.75)]\n",
    "Test_set = dataset[int(len(dataset) * 0.75):]\n",
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassPerceptron():\n",
    "    # Analytics values\n",
    "    precision, recall, accuracy, fbeta_score = {}, {}, 0, {}\n",
    "\n",
    "    def __init__(self, classes, feature_list, feature_data, iterations=100):\n",
    "        self.classes = classes\n",
    "        self.feature_list = feature_list\n",
    "        self.feature_data = feature_data\n",
    "        self.iterations = iterations\n",
    "\n",
    "        # Initialize empty weight vectors, with extra BIAS term.\n",
    "        self.weight_vectors = {c: np.array([0 for _ in range(len(feature_list) + 1)]) for c in self.classes}\n",
    "\n",
    "    def train(self, train_set):\n",
    "        for _ in range(self.iterations):\n",
    "            for category, feature_dic in train_set:\n",
    "                # Format feature values as a vector, with extra BIAS term.\n",
    "                feature_list = [feature_dic[k] for k in self.feature_list]\n",
    "                feature_list.append(1)\n",
    "                feature_vector = np.array(feature_list) #!!!\n",
    "\n",
    "                # Initialize arg_max value, predicted class.\n",
    "                arg_max, predicted_class = 0, self.classes[0]\n",
    "\n",
    "                # Multi-Class Decision Rule:\n",
    "                for c in self.classes:\n",
    "                    current_activation = np.dot(feature_vector, self.weight_vectors[c])\n",
    "                    if current_activation >= arg_max:\n",
    "                        arg_max, predicted_class = current_activation, c\n",
    "\n",
    "                # Update Rule:\n",
    "                if not (category == predicted_class):\n",
    "                    self.weight_vectors[category] = np.add(self.weight_vectors[category], feature_vector)\n",
    "                    self.weight_vectors[predicted_class] = np.subtract(self.weight_vectors[predicted_class], feature_vector)\n",
    "\n",
    "    def predict(self, feature_dict):\n",
    "        feature_list = [feature_dict[k] for k in self.feature_list]\n",
    "        feature_list.append(1)\n",
    "        feature_vector = np.array(feature_list)\n",
    "\n",
    "        # Initialize arg_max value, predicted class.\n",
    "        arg_max, predicted_class = 0, self.classes[0]\n",
    "\n",
    "        # Multi-Class Decision Rule:\n",
    "        for c in self.classes:\n",
    "            current_activation = np.dot(feature_vector, self.weight_vectors[c])\n",
    "            if current_activation >= arg_max:\n",
    "                arg_max, predicted_class = current_activation, c\n",
    "\n",
    "        return predicted_class\n",
    "\n",
    "    def run_analytics(self, test_set):\n",
    "        print(\"CLASSIFIER ANALYSIS: \")\n",
    "        print(\"\")\n",
    "        self.calculate_precision(test_set)\n",
    "        print (\"\")\n",
    "        self.calculate_recall(test_set)\n",
    "        print (\"\")\n",
    "        self.calculate_fbeta_score()\n",
    "        print (\"\")\n",
    "        self.calculate_accuracy(test_set)\n",
    "\n",
    "    def calculate_precision(self, test_set):\n",
    "        test_classes = [f[0] for f in test_set]\n",
    "        correct_counts = {c: 0 for c in test_classes}\n",
    "        total_counts = {c: 0 for c in test_classes}\n",
    "\n",
    "        for feature_dict in test_set:\n",
    "            actual_class = feature_dict[0]\n",
    "            predicted_class = self.predict(feature_dict[1])\n",
    "\n",
    "            if actual_class == predicted_class:\n",
    "                correct_counts[actual_class] += 1\n",
    "                total_counts[actual_class] += 1\n",
    "            else:\n",
    "                total_counts[predicted_class] += 1\n",
    "\n",
    "\n",
    "        print(\"PRECISION STATISTICS:\")\n",
    "\n",
    "        for c in correct_counts:\n",
    "            self.precision[c] = (correct_counts[c] * 1.0) / (total_counts[c] * 1.0)\n",
    "            print(\"%s Class Precision:\" % (c), self.precision[c])\n",
    "\n",
    "    def calculate_recall(self, test_set):\n",
    "        test_classes = [f[0] for f in test_set]\n",
    "        correct_counts = {c: 0 for c in test_classes}\n",
    "        total_counts = {c: 0 for c in test_classes}\n",
    "\n",
    "        for feature_dict in test_set:\n",
    "            actual_class = feature_dict[0]\n",
    "            predicted_class = self.predict(feature_dict[1])\n",
    "\n",
    "            if actual_class == predicted_class:\n",
    "                correct_counts[actual_class] += 1\n",
    "                total_counts[actual_class] += 1\n",
    "            else:\n",
    "                total_counts[actual_class] += 1\n",
    "\n",
    "        print(\"RECALL STATISTICS:\")\n",
    "\n",
    "        for c in correct_counts:\n",
    "            self.recall[c] = (correct_counts[c] * 1.0) / (total_counts[c] * 1.0)\n",
    "            print(\"%s Class Recall:\" % (c), self.recall[c])\n",
    "\n",
    "    def calculate_accuracy(self, test_set):\n",
    "        correct, incorrect = 0, 0\n",
    "        for feature_dict in test_set:\n",
    "            actual_class = feature_dict[0]\n",
    "            predicted_class = self.predict(feature_dict[1])\n",
    "\n",
    "            if actual_class == predicted_class:\n",
    "                correct += 1\n",
    "            else:\n",
    "                incorrect += 1\n",
    "\n",
    "        print(\"ACCURACY:\")\n",
    "        print(\"Model Accuracy:\", (correct * 1.0) / ((correct + incorrect) * 1.0))\n",
    "\n",
    "    def calculate_fbeta_score(self):\n",
    "        print(\"F-BETA SCORES: \")\n",
    "        for c in self.precision:\n",
    "            self.fbeta_score[c] = 2 * ((self.precision[c] * self.recall[c]) / (self.precision[c] + self.recall[c]))\n",
    "            print(\"%s Class F-Beta Score:\", self.fbeta_score[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MultiClassPerceptron(classes, feature_list, dataset)\n",
    "classifier.train(Train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFIER ANALYSIS: \n",
      "\n",
      "PRECISION STATISTICS:\n",
      "1 Class Precision: 1.0\n",
      "0 Class Precision: 1.0\n",
      "2 Class Precision: 1.0\n",
      "\n",
      "RECALL STATISTICS:\n",
      "1 Class Recall: 1.0\n",
      "0 Class Recall: 1.0\n",
      "2 Class Recall: 1.0\n",
      "\n",
      "F-BETA SCORES: \n",
      "%s Class F-Beta Score: 1.0\n",
      "%s Class F-Beta Score: 1.0\n",
      "%s Class F-Beta Score: 1.0\n",
      "\n",
      "ACCURACY:\n",
      "Model Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.run_analytics(Test_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
